{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":963111,"sourceType":"datasetVersion","datasetId":524875},{"sourceId":963129,"sourceType":"datasetVersion","datasetId":524890}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:29.050195Z","iopub.execute_input":"2024-04-23T05:05:29.050552Z","iopub.status.idle":"2024-04-23T05:05:29.809816Z","shell.execute_reply.started":"2024-04-23T05:05:29.050524Z","shell.execute_reply":"2024-04-23T05:05:29.808906Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv('/kaggle/input/tuberculosis-chest-xrays-shenzhen/shenzhen_metadata.csv')\nbase_path='/kaggle/input/tuberculosis-chest-xrays-shenzhen/images/images/'\ndf1['equalized_filename'] = df1['study_id'].apply(lambda x: base_path+x)\ndf2=pd.read_csv('/kaggle/input/tuberculosis-chest-xrays-montgomery/montgomery_metadata.csv')\nbase_path='/kaggle/input/tuberculosis-chest-xrays-montgomery/images/images/'\ndf2['equalized_filename'] = df2['study_id'].apply(lambda x: base_path+x)\ndf=pd.concat([df1, df2], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:29.811693Z","iopub.execute_input":"2024-04-23T05:05:29.812554Z","iopub.status.idle":"2024-04-23T05:05:29.852331Z","shell.execute_reply.started":"2024-04-23T05:05:29.812513Z","shell.execute_reply":"2024-04-23T05:05:29.851464Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df['target']=df['findings'].apply(lambda x:0 if x=='normal' else 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:29.853478Z","iopub.execute_input":"2024-04-23T05:05:29.853789Z","iopub.status.idle":"2024-04-23T05:05:29.859859Z","shell.execute_reply.started":"2024-04-23T05:05:29.853763Z","shell.execute_reply":"2024-04-23T05:05:29.858813Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:29.862354Z","iopub.execute_input":"2024-04-23T05:05:29.862729Z","iopub.status.idle":"2024-04-23T05:05:29.879856Z","shell.execute_reply.started":"2024-04-23T05:05:29.862704Z","shell.execute_reply":"2024-04-23T05:05:29.879013Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            study_id     sex  age findings  \\\n0  CHNCXR_0001_0.png    Male   45   normal   \n1  CHNCXR_0002_0.png    Male   63   normal   \n2  CHNCXR_0003_0.png  Female   48   normal   \n3  CHNCXR_0004_0.png    Male   58   normal   \n4  CHNCXR_0005_0.png    Male   28   normal   \n\n                                  equalized_filename gender  target  \n0  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN       0  \n1  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN       0  \n2  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN       0  \n3  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN       0  \n4  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>findings</th>\n      <th>equalized_filename</th>\n      <th>gender</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CHNCXR_0001_0.png</td>\n      <td>Male</td>\n      <td>45</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHNCXR_0002_0.png</td>\n      <td>Male</td>\n      <td>63</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CHNCXR_0003_0.png</td>\n      <td>Female</td>\n      <td>48</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CHNCXR_0004_0.png</td>\n      <td>Male</td>\n      <td>58</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHNCXR_0005_0.png</td>\n      <td>Male</td>\n      <td>28</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:29.880836Z","iopub.execute_input":"2024-04-23T05:05:29.881119Z","iopub.status.idle":"2024-04-23T05:05:41.613896Z","shell.execute_reply.started":"2024-04-23T05:05:29.881094Z","shell.execute_reply":"2024-04-23T05:05:41.613062Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-04-23 05:05:31.281079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 05:05:31.281171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 05:05:31.381909: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"df['target'] = df['target'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:41.614999Z","iopub.execute_input":"2024-04-23T05:05:41.615548Z","iopub.status.idle":"2024-04-23T05:05:41.621377Z","shell.execute_reply.started":"2024-04-23T05:05:41.615514Z","shell.execute_reply":"2024-04-23T05:05:41.620438Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:41.622486Z","iopub.execute_input":"2024-04-23T05:05:41.622735Z","iopub.status.idle":"2024-04-23T05:05:41.657743Z","shell.execute_reply.started":"2024-04-23T05:05:41.622713Z","shell.execute_reply":"2024-04-23T05:05:41.656694Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            study_id     sex  age                      findings  \\\n0  CHNCXR_0616_1.png    Male   54  PTB in the right upper field   \n1  CHNCXR_0609_1.png    Male   26   PTB in the left upper field   \n2  CHNCXR_0277_0.png    Male   47                        normal   \n3  CHNCXR_0014_0.png    Male   39                        normal   \n4  CHNCXR_0549_1.png  Female   63                 bilateral PTB   \n\n                                  equalized_filename gender target  \n0  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  \n1  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  \n2  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      0  \n3  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      0  \n4  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>findings</th>\n      <th>equalized_filename</th>\n      <th>gender</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CHNCXR_0616_1.png</td>\n      <td>Male</td>\n      <td>54</td>\n      <td>PTB in the right upper field</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHNCXR_0609_1.png</td>\n      <td>Male</td>\n      <td>26</td>\n      <td>PTB in the left upper field</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CHNCXR_0277_0.png</td>\n      <td>Male</td>\n      <td>47</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CHNCXR_0014_0.png</td>\n      <td>Male</td>\n      <td>39</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHNCXR_0549_1.png</td>\n      <td>Female</td>\n      <td>63</td>\n      <td>bilateral PTB</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:41.659048Z","iopub.execute_input":"2024-04-23T05:05:41.659340Z","iopub.status.idle":"2024-04-23T05:05:41.671699Z","shell.execute_reply.started":"2024-04-23T05:05:41.659315Z","shell.execute_reply":"2024-04-23T05:05:41.670640Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            study_id     sex  age                      findings  \\\n0  CHNCXR_0616_1.png    Male   54  PTB in the right upper field   \n1  CHNCXR_0609_1.png    Male   26   PTB in the left upper field   \n2  CHNCXR_0277_0.png    Male   47                        normal   \n3  CHNCXR_0014_0.png    Male   39                        normal   \n4  CHNCXR_0549_1.png  Female   63                 bilateral PTB   \n\n                                  equalized_filename gender target  \n0  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  \n1  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  \n2  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      0  \n3  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      0  \n4  /kaggle/input/tuberculosis-chest-xrays-shenzhe...    NaN      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>findings</th>\n      <th>equalized_filename</th>\n      <th>gender</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CHNCXR_0616_1.png</td>\n      <td>Male</td>\n      <td>54</td>\n      <td>PTB in the right upper field</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHNCXR_0609_1.png</td>\n      <td>Male</td>\n      <td>26</td>\n      <td>PTB in the left upper field</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CHNCXR_0277_0.png</td>\n      <td>Male</td>\n      <td>47</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CHNCXR_0014_0.png</td>\n      <td>Male</td>\n      <td>39</td>\n      <td>normal</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHNCXR_0549_1.png</td>\n      <td>Female</td>\n      <td>63</td>\n      <td>bilateral PTB</td>\n      <td>/kaggle/input/tuberculosis-chest-xrays-shenzhe...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Split the data into training and validation sets\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)\n\n# Set up data generators\nbatch_size = 32\nimage_size = (512, 512)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='equalized_filename',\n    y_col='target',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary',  # Set class_mode to 'binary'\n    subset='training',\n    shuffle=True\n)\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n    val_df,\n    x_col='equalized_filename',\n    y_col='target',\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary',  # Set class_mode to 'binary'\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:41.673158Z","iopub.execute_input":"2024-04-23T05:05:41.673567Z","iopub.status.idle":"2024-04-23T05:05:44.525081Z","shell.execute_reply.started":"2024-04-23T05:05:41.673542Z","shell.execute_reply":"2024-04-23T05:05:44.524181Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 512 validated image filenames belonging to 2 classes.\nFound 32 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import cv2\n# def histogram_equalization(image_path):\n#     # Read the image in grayscale\n#     img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    \n#     # Apply histogram equalization\n#     equalized_img = cv2.equalizeHist(img)\n    \n#     # Display the original and equalized images\n#     plt.figure(figsize=(10, 5))\n#     plt.subplot(1, 2, 1)\n#     plt.imshow(img, cmap='gray')\n#     plt.title('Original Image')\n    \n#     plt.subplot(1, 2, 2)\n#     plt.imshow(equalized_img, cmap='gray')\n#     plt.title('Equalized Image')\n    \n#     plt.show()\n# histogram_equalization(df['equalized_filename'][100])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:44.528526Z","iopub.execute_input":"2024-04-23T05:05:44.528858Z","iopub.status.idle":"2024-04-23T05:05:44.533502Z","shell.execute_reply.started":"2024-04-23T05:05:44.528833Z","shell.execute_reply":"2024-04-23T05:05:44.532516Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:44.534697Z","iopub.execute_input":"2024-04-23T05:05:44.535000Z","iopub.status.idle":"2024-04-23T05:05:58.500507Z","shell.execute_reply.started":"2024-04-23T05:05:44.534974Z","shell.execute_reply":"2024-04-23T05:05:58.499315Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.22.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.26.4)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.10.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.11.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.2.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.12.9)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet) (3.1.1)\nDownloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nDownloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m901.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n\n\n\n\n# Train the model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:58.502043Z","iopub.execute_input":"2024-04-23T05:05:58.502373Z","iopub.status.idle":"2024-04-23T05:05:58.612456Z","shell.execute_reply.started":"2024-04-23T05:05:58.502342Z","shell.execute_reply":"2024-04-23T05:05:58.611676Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained EfficientNetB0 model\nbase_model_e1 = efn.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n\n# Optionally freeze the layers of the base model\nfor layer in base_model_e1.layers:\n    layer.trainable = False\n\n# Add custom classification head\nmodel_e1 = Sequential([\n    Input(shape=(512, 512, 3)),\n    base_model_e1,\n    GlobalAveragePooling2D(),\n    Dense(256, activation='relu'),\n    Dense(1, activation='sigmoid')  # Change the number of units according to your task\n])\n\n# Compile the model\nmodel_e1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Display the model summary\nmodel_e1.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:05:58.613676Z","iopub.execute_input":"2024-04-23T05:05:58.614590Z","iopub.status.idle":"2024-04-23T05:06:01.336794Z","shell.execute_reply.started":"2024-04-23T05:05:58.614561Z","shell.execute_reply":"2024-04-23T05:06:01.335896Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n\u001b[1m16804768/16804768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ efficientnet-b0 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1280\u001b[0m)   │     \u001b[38;5;34m4,049,564\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ efficientnet-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,564</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,377,757\u001b[0m (16.70 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,377,757</span> (16.70 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,193\u001b[0m (1.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,193</span> (1.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,564\u001b[0m (15.45 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,564</span> (15.45 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"history_efficientNet = model_e1.fit(\n    train_generator,\n    epochs=20,\n    validation_data=validation_generator,\n    steps_per_epoch=len(train_generator),\n    validation_steps=len(validation_generator)\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:06:01.337974Z","iopub.execute_input":"2024-04-23T05:06:01.338252Z","iopub.status.idle":"2024-04-23T05:23:41.963332Z","shell.execute_reply.started":"2024-04-23T05:06:01.338228Z","shell.execute_reply":"2024-04-23T05:23:41.962455Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713848885.057825      93 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1713848885.110499      93 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 5s/step - accuracy: 0.6430 - loss: 0.6554 - val_accuracy: 0.7188 - val_loss: 0.5533\nEpoch 2/20\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713848956.884022      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 3/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.7287 - loss: 0.5677 - val_accuracy: 0.8750 - val_loss: 0.4765\nEpoch 4/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 5/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3s/step - accuracy: 0.8037 - loss: 0.4505 - val_accuracy: 0.8438 - val_loss: 0.3906\nEpoch 6/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 7/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8124 - loss: 0.4142 - val_accuracy: 0.9062 - val_loss: 0.3939\nEpoch 8/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 9/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - accuracy: 0.8236 - loss: 0.4230 - val_accuracy: 0.8750 - val_loss: 0.3451\nEpoch 10/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 11/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - accuracy: 0.8198 - loss: 0.4265 - val_accuracy: 0.8750 - val_loss: 0.3549\nEpoch 12/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 13/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.7920 - loss: 0.4275 - val_accuracy: 0.8438 - val_loss: 0.3431\nEpoch 14/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 15/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - accuracy: 0.8367 - loss: 0.3836 - val_accuracy: 0.8750 - val_loss: 0.3561\nEpoch 16/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 17/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.8452 - loss: 0.3803 - val_accuracy: 0.8125 - val_loss: 0.4055\nEpoch 18/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 19/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - accuracy: 0.8415 - loss: 0.4058 - val_accuracy: 0.8438 - val_loss: 0.3600\nEpoch 20/20\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","output_type":"stream"}]}]}